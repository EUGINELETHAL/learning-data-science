{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A Deep Neural Network (DNN) model to discern Iris flowers\n",
    "We'll build a DNN model to predict the type of Iris flower species given only a flower's natural features(sepal and petal length).\n",
    "\n",
    "We will use Google's Tensorflow: an open source machine learning tool for everyone.\n",
    "\n",
    "The types of flowers we would like to distunguish is Iris Versicolour, Iris Virginica, Iris Setosa. \n",
    "\n",
    "The flowers look like this:\n",
    "\n",
    "* Iris Virginica\n",
    "![Iris Virginica](images/178px-Iris_virginica.jpg)\n",
    "\n",
    "* Iris Versicolor\n",
    "![Iris_versicolor](images/193px-Iris_versicolor_3.jpg)\n",
    "\n",
    "* Iris Setosa\n",
    "![Iris Kosaciec](images/109px-Kosaciec_szczecinkowaty_Iris_setosa.jpg)\n",
    "\n",
    "The data columns we have are:\n",
    "* sepal length in cm\n",
    "* sepal width in cm\n",
    "* petal length in cm\n",
    "* petal width in cm\n",
    "\n",
    "These data points will be used to train the model and test its accuracy.\n",
    "\n",
    "Time to write some Neural Nets!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n",
      "       0    1    2    3  4\n",
      "50   7.9  3.8  6.4  2.0  2\n",
      "95   4.4  2.9  1.4  0.2  0\n",
      "143  6.4  3.2  5.3  2.3  2\n",
      "89   6.1  3.0  4.6  1.4  1\n",
      "30   5.9  3.0  4.2  1.5  1\n",
      "[120, 4, 'setosa', 'versicolor', 'virginica']\n",
      "[30, 4, 'setosa', 'versicolor', 'virginica']\n"
     ]
    }
   ],
   "source": [
    "# Step 1: split the data into training and testing data\n",
    "# Key points to note:\n",
    "############ In the data frame that we wish to form,\n",
    "############ * Setosa's value = 0, Versicolor = 1 and Virginica = 2\n",
    "########### * The species column will be changed to contain these values before we split the data.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# read data from the csv file\n",
    "actual_data = pd.read_csv(\"iris.csv\")\n",
    "data = pd.read_csv(\"iris.csv\", skiprows=[0], header=None)\n",
    "labels_data = pd.read_csv(\"iris.csv\", usecols=[4], skiprows=[0], header=None)\n",
    "labels = np.unique(np.array(labels_data, 'str'))\n",
    "print (labels)\n",
    "\n",
    "# iterate through each row, changing the last column (4) to have integers instead of flower names\n",
    "for index, row in data.iterrows():\n",
    "    if row[4] == labels[0]:\n",
    "        data.loc[index, 4] = 0\n",
    "    elif row[4] == labels[1]:\n",
    "        data.loc[index, 4] = 1\n",
    "    else:\n",
    "        data.loc[index, 4] = 2\n",
    "\n",
    "# shuffle the newly formatted data\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "y = actual_data.species\n",
    "\n",
    "# split that data, 80-20 rule\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.2)\n",
    "print (X_test.head())\n",
    "\n",
    "# write the split data to csv\n",
    "# but first create a custom header for the training and test csv files\n",
    "# and omit the species column from the header since that's what we want to predict (hence the \"- 1\")\n",
    "X_train_header = list((len(X_train.index), len(X_train.columns) - 1))  + list(labels)\n",
    "X_test_header = list((len(X_test.index), len(X_test.columns) - 1)) + list(labels)\n",
    "print (X_train_header)\n",
    "print (X_test_header)\n",
    "\n",
    "# write the split data to csv files\n",
    "X_train.to_csv(\"iris_training.csv\", index=False, index_label=False, header=X_train_header)\n",
    "X_test.to_csv(\"iris_test.csv\", index=False, index_label=False, header=X_test_header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason why we had to format the header of the training and test csv to be \n",
    "`(row length, column length, 'setosa', 'versicolor', 'virginica')` is to \n",
    "make the `load_csv_with_header` function be able to read our data. Data preparation matters. :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 2 1 1 1 0 1 2 0 2 0 2 2 0 1 0 1 1 0 0 2 0 2 1 0 1 1 2 0]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.learn.python.learn.datasets import base\n",
    "\n",
    "# Data files containing our sepal and petal features\n",
    "IRIS_TRAINING = \"iris_training.csv\"\n",
    "IRIS_TEST = \"iris_test.csv\"\n",
    "\n",
    "training_set = base.load_csv_with_header(\n",
    "    filename=IRIS_TRAINING, \n",
    "    features_dtype=np.float32, \n",
    "    target_dtype=np.int)\n",
    "\n",
    "test_set = base.load_csv_with_header(\n",
    "    filename=IRIS_TEST,\n",
    "    features_dtype=np.float32,\n",
    "    target_dtype=np.int)\n",
    "\n",
    "print(test_set.target)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Specify that all feature columns have real-value data\n",
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we build the 3 layer Deep Nueral Network classfier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1c21f97320>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/iris_model'}\n"
     ]
    }
   ],
   "source": [
    "classifier = tf.contrib.learn.DNNClassifier(\n",
    "    feature_columns=featured_columns,\n",
    "    hidden_units=[10, 20, 10],\n",
    "    n_classes=3,\n",
    "    model_dir=\"/tmp/iris_model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the training inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training_inputs():\n",
    "    x = tf.constant(training_set.data)\n",
    "    y = tf.constant(training_set.target)\n",
    "    \n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then next step is to fit the model with the training data. Fitting is where the model is trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/iris_model/model.ckpt-14000\n",
      "INFO:tensorflow:Saving checkpoints for 14001 into /tmp/iris_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.04674709, step = 14001\n",
      "INFO:tensorflow:global_step/sec: 783.448\n",
      "INFO:tensorflow:loss = 0.046954535, step = 14101 (0.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 860.518\n",
      "INFO:tensorflow:loss = 0.047011122, step = 14201 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 890.17\n",
      "INFO:tensorflow:loss = 0.046789907, step = 14301 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 637.91\n",
      "INFO:tensorflow:loss = 0.046695717, step = 14401 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 778.683\n",
      "INFO:tensorflow:loss = 0.04667021, step = 14501 (0.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 735.148\n",
      "INFO:tensorflow:loss = 0.046662346, step = 14601 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 890.48\n",
      "INFO:tensorflow:loss = 0.046659503, step = 14701 (0.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 678.196\n",
      "INFO:tensorflow:loss = 0.0466594, step = 14801 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 724.953\n",
      "INFO:tensorflow:loss = 0.04666304, step = 14901 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 789.559\n",
      "INFO:tensorflow:loss = 0.046675432, step = 15001 (0.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 579.811\n",
      "INFO:tensorflow:loss = 0.04671428, step = 15101 (0.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 680.94\n",
      "INFO:tensorflow:loss = 0.04681112, step = 15201 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 936.521\n",
      "INFO:tensorflow:loss = 0.04689629, step = 15301 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 883.049\n",
      "INFO:tensorflow:loss = 0.0468172, step = 15401 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 762.016\n",
      "INFO:tensorflow:loss = 0.04672064, step = 15501 (0.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 755.378\n",
      "INFO:tensorflow:loss = 0.046678133, step = 15601 (0.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 728.151\n",
      "INFO:tensorflow:loss = 0.0466625, step = 15701 (0.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 746.197\n",
      "INFO:tensorflow:loss = 0.046656676, step = 15801 (0.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 680.698\n",
      "INFO:tensorflow:loss = 0.046654765, step = 15901 (0.151 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 16000 into /tmp/iris_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.046655238.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNClassifier(params={'head': <tensorflow.contrib.learn.python.learn.estimators.head._MultiClassHead object at 0x1c21f97358>, 'hidden_units': [10, 20, 10], 'feature_columns': (_RealValuedColumn(column_name='', dimension=4, default_value=None, dtype=tf.float32, normalizer=None),), 'optimizer': None, 'activation_fn': <function relu at 0x1160d4d90>, 'dropout': None, 'gradient_clip_norm': None, 'embedding_lr_multipliers': None, 'input_layer_min_slice_size': None})"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the classifier with the training data\n",
    "classifier.fit(input_fn=training_inputs, steps=2000)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define test inputs\n",
    "def test_inputs():\n",
    "    x = tf.constant(test_set.data)\n",
    "    y = tf.constant(test_set.target)\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training, we evaluate the accuracy of our trained model. \n",
    "We do this using the evaluate method. It takes in the test input data and target to build its input data pipeline. After measuring the model's accuracy, it returns a dictionary containing the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-03-05-11:23:42\n",
      "INFO:tensorflow:Restoring parameters from /tmp/iris_model/model.ckpt-10000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-05-11:23:43\n",
      "INFO:tensorflow:Saving dict for global step 10000: accuracy = 1.0, global_step = 10000, loss = 0.015831133\n",
      "Accuracy score 1.0\n"
     ]
    }
   ],
   "source": [
    "# evaluate the classifier's accuracy\n",
    "accuracy_score = classifier.evaluate(input_fn=test_inputs, steps=1)['accuracy']\n",
    "print (\"Accuracy score\", accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to see if our model can predict the type of Iris flower given a new flower sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Classify two new flower samples.\n",
    "def new_flower_samples():\n",
    "    return np.array(\n",
    "        [[6.4, 3.2, 4.5, 1.5],\n",
    "        [5.8, 3.1, 5.0, 1.7]], dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/iris_model/model.ckpt-10000\n",
      "[1, 2]\n"
     ]
    }
   ],
   "source": [
    "# Predict the type of Iris flower\n",
    "prediction = classifier.predict_classes(input_fn=new_flower_samples)\n",
    "print (list(prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We made it!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try creating a Linear model and compare it's prediction with that of the DNN we just created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a built in linear model classifier\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
